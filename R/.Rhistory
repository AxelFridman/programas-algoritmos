modPesoEnEdadBlan = lm(WEIGHT~poly(AGE,2), data=whites)
modPesoEnEdadNeg = lm(WEIGHT~poly(AGE,2), data=blacks)
plot(whites$AGE,whites$WEIGHT,  xlab = "Edad en anios", ylab = "Peso en KG", main="Peso en funcion de edad de blancos y de color")
points(blacks$AGE,blacks$WEIGHT, pch=19)
lines(puntosIntervalo, predict(modPesoEnEdadBlan, newdata = dataFrameEvaluar), col='light blue', lwd=3)
lines(puntosIntervalo, predict(modPesoEnEdadNeg, newdata = dataFrameEvaluar), col='pink', lwd=3)
library(class)
library(viridis) # para tener los colores
library(ggplot2) # para tener el alpha para regular opacidad
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Atributo x1', ylab = 'Atributo x2', main = 'Scatterplot por clases', pch = shapes, cex = 0.8)
legend("topleft",
legend = c('Clase 1', 'Clase 2', 'Clase 3'),
pch = c(15, 16, 17),
col =  viridis(3))
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Atributo x1', ylab = 'Atributo x2', main = 'Scatterplot por clases', pch = shapes, cex = 0.8)
legend("topleft",
legend = c('Clase 1', 'Clase 2', 'Clase 3'),
pch = c(15, 16, 17),
col =  viridis(3))
points(c(6.2), c(3.2), pch = 1, col = "coral")
library(knitr)
include_graphics('iris.png')
library(knitr)
library(viridis) # para tener los colores
library(ggplot2) # para tener el alpha para regular opacidad
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Atributo x1', ylab = 'Atributo x2', main = 'Scatterplot por clases', pch = shapes, cex = 0.8)
legend("topleft",
legend = c('Clase 1', 'Clase 2', 'Clase 3'),
pch = c(15, 16, 17),
col =  viridis(3))
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Atributo x1', ylab = 'Atributo x2', main = 'Scatterplot por clases', pch = shapes, cex = 0.8)
legend("topleft",
legend = c('Clase 1', 'Clase 2', 'Clase 3'),
pch = c(15, 16, 17),
col =  viridis(3))
points(c(6.2), c(3.2), pch = 1, col = "coral")
library(knitr)
iris
set.seed(111) # para poder replicar
summary(iris)
iris
par(mfrow = c(2, 2))
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Petal.Length[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Petal Length')
hist(iris$Petal.Length[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Petal.Length[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
##########
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Petal.Width[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Petal Width')
hist(iris$Petal.Width[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Petal.Width[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
legend('topright',  legend = unique(iris$Species),
fill = viridis(3), title="Clases")
##########
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Sepal.Length[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Sepal Length')
hist(iris$Sepal.Length[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Sepal.Length[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
##########
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Sepal.Width[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Sepal Width')
hist(iris$Sepal.Width[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Sepal.Width[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
clasificador_iris <- function(datos){
pet_len = datos[3]
if(pet_len <= 2.5){
clase = 'setosa'---
title: "R Notebook"
}
else if(pet_len <= 4.5){
clase = 'versicolor'
}
else{
clase = 'virginica'
}
return(clase)
}
flor = iris[122, -5] # le saco la quinta columna, porque el clasificador toma las primeras cuatro
clase_flor = iris$Species[122]
clase_asignada_flor = clasificador_iris(flor)
print(flor)
print(clase_flor)
print(clase_asignada_flor)
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Petal.Length[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = 'Histograma de Petal Length por variedad', xlab = 'Petal Length')
hist(iris$Petal.Length[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Petal.Length[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
legend('topright',  legend = unique(iris$Species),
fill = viridis(3), title="Clases")
abline(v = 2.5, col = "coral")
abline(v = 4.5, col = "coral")
nuevo_iris <- iris
nuevo_iris$clase_asig <- apply(nuevo_iris[, -5], 1, clasificador_iris)
nuevo_iris <- iris
nuevo_iris$clase_asig <- apply(nuevo_iris[, -5], 2, clasificador_iris)
nuevo_iris <- iris
nuevo_iris$clase_asig <- apply(nuevo_iris[, -5], 1, clasificador_iris)
b = seq(0,8, 0.1)
colores = viridis(3)
hist(nuevo_iris$Petal.Length[nuevo_iris$clase_asig == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = 'Histograma de Petal Length por variedad asignada', xlab = 'Petal Length')
hist(nuevo_iris$Petal.Length[nuevo_iris$clase_asig == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(nuevo_iris$Petal.Length[nuevo_iris$clase_asig == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
legend('topright',  legend = unique(nuevo_iris$clase_asig),
fill = viridis(3), title="Clases asignadas")
library(viridis) # para tener los colores
library(ggplot2) # para tener el alpha para regular opacidad
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Atributo x1', ylab = 'Atributo x2', main = 'Scatterplot por clases', pch = shapes, cex = 0.8)
legend("topleft",
legend = c('Clase 1', 'Clase 2', 'Clase 3'),
pch = c(15, 16, 17),
col =  viridis(3))
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Atributo x1', ylab = 'Atributo x2', main = 'Scatterplot por clases', pch = shapes, cex = 0.8)
legend("topleft",
legend = c('Clase 1', 'Clase 2', 'Clase 3'),
pch = c(15, 16, 17),
col =  viridis(3))
points(c(6.2), c(3.2), pch = 1, col = "coral")
library(knitr)
iris
set.seed(111) # para poder replicar
summary(iris)
iris
par(mfrow = c(2, 2))
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Petal.Length[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Petal Length')
hist(iris$Petal.Length[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Petal.Length[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
##########
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Petal.Width[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Petal Width')
hist(iris$Petal.Width[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Petal.Width[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
legend('topright',  legend = unique(iris$Species),
fill = viridis(3), title="Clases")
##########
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Sepal.Length[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Sepal Length')
hist(iris$Sepal.Length[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Sepal.Length[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
##########
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Sepal.Width[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = '', xlab = 'Sepal Width')
hist(iris$Sepal.Width[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Sepal.Width[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
clasificador_iris <- function(datos){
pet_len = datos[3]
if(pet_len <= 2.5){
clase = 'setosa'---
title: "R Notebook"
}
else if(pet_len <= 4.5){
clase = 'versicolor'
}
else{
clase = 'virginica'
}
return(clase)
}
flor = iris[122, -5] # le saco la quinta columna, porque el clasificador toma las primeras cuatro
clase_flor = iris$Species[122]
clase_asignada_flor = clasificador_iris(flor)
print(flor)
print(clase_flor)
print(clase_asignada_flor)
b = seq(0,8, 0.1)
colores = viridis(3)
hist(iris$Petal.Length[iris$Species == 'setosa'], breaks = b,  xlim = c(0,8), col = alpha(colores[1],0.5), ylim = c(0,15), main = 'Histograma de Petal Length por variedad', xlab = 'Petal Length')
hist(iris$Petal.Length[iris$Species == 'versicolor'], breaks = b, add = TRUE, col = alpha(colores[2], 0.5), ylim = c(0, 5), main = '')
hist(iris$Petal.Length[iris$Species == 'virginica'], breaks = b, add = TRUE,  col = alpha(colores[3], 0.5), ylim = c(0, 5), xlim = c(0,8), main = '')
legend('topright',  legend = unique(iris$Species),
fill = viridis(3), title="Clases")
abline(v = 2.5, col = "coral")
abline(v = 4.5, col = "coral")
nuevo_iris <- iris
nuevo_iris$clase_asig <- apply(nuevo_iris[, -5], 1, clasificador_iris)
clases = unique(iris$Species)
matriz_confusion <- matrix(NA, 3, 3)
dimnames(matriz_confusion) <- list(clases, clases)
for(i in 1:3){
for(j in 1:3){
filtro = (nuevo_iris$Species == clases[i] & nuevo_iris$clase_asig == clases[j])
cuenta = nrow(nuevo_iris[filtro,])
matriz_confusion[i, j] = cuenta
}
}
matriz_confusion
exactitud <- mean(nuevo_iris$Species == nuevo_iris$clase_asig)
exactitud
exactitud <- function(clasif, data, labels){
predichos = apply(data, 1, clasif)
cuenta = mean(predichos == labels)
return(cuenta)
}
exactitud(clasificador_iris, iris[,-5], iris$Species)
posibles_cortes = seq(4, 6, 0.1)
resultados_exact = c()
for(c in posibles_cortes){
clasificador_iris_c <- function(datos){
pet_len = datos[3]
if(pet_len <= 2.5){
clase = 'setosa'
}
else if(pet_len <= c){
clase = 'versicolor'
}
else{
clase = 'virginica'
}
return(clase)
}
exactitud_c = exactitud(clasificador_iris_c, iris[,-5], iris$Species)
resultados_exact = c(resultados_exact, exactitud_c)
}
plot(posibles_cortes, resultados_exact, pch = 19, cex = 0.5, main = 'Exactitud en función del corte elegido', xlab = 'Corte', ylab = 'Exactitud')
lines(posibles_cortes, resultados_exact)
plot(posibles_cortes[5:15], resultados_exact[5:15], pch = 19, cex = 0.5, main = 'Exactitud en función del corte elegido', xlab = 'Corte', ylab = 'Exactitud')
lines(posibles_cortes[5:15], resultados_exact[5:15])
i = which.max(resultados_exact)
posibles_cortes[i]
shapes = c(15, 16, 17)
shapes <- shapes[as.numeric(iris$Species)]
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Sepal Length', ylab = 'Sepal Width', main = 'Scatterplot de Sepal length y width por variedad', pch = shapes, cex = 0.8)
legend("topleft",
legend = unique(iris$Species),
pch = c(15, 16, 17),
col =  viridis(3))
points(c(5.75), c(2.5), pch = 19, col = "coral")
points(c(5.75), c(2.5), pch = 1, cex = 3.5, col = "black")
text(c(6), c(2.5), 'k = 1')
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Sepal Length', ylab = 'Sepal Width', main = 'Scatterplot de Sepal length y width por variedad', pch = shapes, cex = 0.8)
legend("topleft",
legend = unique(iris$Species),
pch = c(15, 16, 17),
col =  viridis(3))
points(c(5.75), c(2.5), pch = 19, col = "coral")
points(c(5.75), c(2.5), pch = 1, cex = 5.1, col = "black")
text(c(6), c(2.5), 'k = 3')
plot(iris$Sepal.Length, iris$Sepal.Width, col = viridis(3)[iris$Species], xlab = 'Sepal Length', ylab = 'Sepal Width', main = 'Scatterplot de Sepal length y width por variedad', pch = shapes, cex = 0.8)
legend("topleft",
legend = unique(iris$Species),
pch = c(15, 16, 17),
col =  viridis(3))
points(c(5.75), c(2.5), pch = 19, col = "coral")
points(c(5.75), c(2.5), pch = 1, cex = 8.6, col = "black")
text(c(6.1), c(2.5), 'k = 5')
library(class) # para el clasificador knn
train =  iris[, -5] # saco la columna con la etiqueta
test =  iris[, -5]
labels_train = iris[,5] # guardo las etiquetas
clasif_iris <- knn(train = train, test = test, cl = labels_train, k = 1)
summary(clasif_iris)
clasif_iris <- knn(train = train, test = test, cl = labels_train, k = 3)
summary(clasif_iris)
clasif_iris <- knn(train = train, test = test, cl = labels_train, k = 5)
summary(clasif_iris)
clasif_iris <- knn(train = train, test = test, cl = labels_train, k = 10)
summary(clasif_iris)
library(caret) # para la confusionMatrix
install.packages(caret)
install.packages("caret")
library(caret) # para la confusionMatrix
labels_test = iris[,5]
confusionMatrix(clasif_iris, labels_test)
confusionMatrix(clasif_iris, labels_test)$overall[[1]]
Nrep = 20
Ntest = 30
max_val = 50
valores = 1:max_val
resultados_crossval_train = matrix(NA, length(valores), Nrep)
resultados_crossval_test = matrix(NA, length(valores), Nrep)
for(n in 1:Nrep){
indices = sample(seq(1, nrow(iris)), Ntest)
test = iris[indices, -5]
train = iris[-indices, -5]
test_labels = iris$Species[indices]
train_labels = iris$Species[-indices]
for(k in 1:max_val){
clasificador_iris_k_train <- knn(train = train, test = train, cl = train_labels, k = k)
clasificador_iris_k_test <- knn(train = train, test = test, cl = train_labels, k = k)
exactitud_train = confusionMatrix(clasificador_iris_k_train, train_labels)$overall[[1]]
exactitud_test = confusionMatrix(clasificador_iris_k_test, test_labels)$overall[[1]]
resultados_crossval_train[k, n] = exactitud_train
resultados_crossval_test[k, n] = exactitud_test
}
}
exact_train = rowMeans(resultados_crossval_train)
exact_test = rowMeans(resultados_crossval_test)
Nrep = 20
Ntest = 30
max_val = 50
valores = 1:max_val
resultados_crossval_train = matrix(NA, length(valores), Nrep)
resultados_crossval_test = matrix(NA, length(valores), Nrep)
for(n in 1:Nrep){
indices = sample(seq(1, nrow(iris)), Ntest)
test = iris[indices, -5]
train = iris[-indices, -5]
test_labels = iris$Species[indices]
train_labels = iris$Species[-indices]
for(k in 1:max_val){
clasificador_iris_k_train <- knn(train = train, test = train, cl = train_labels, k = k)
clasificador_iris_k_test <- knn(train = train, test = test, cl = train_labels, k = k)
exactitud_train = confusionMatrix(clasificador_iris_k_train, train_labels)$overall[[1]]
exactitud_test = confusionMatrix(clasificador_iris_k_test, test_labels)$overall[[1]]
resultados_crossval_train[k, n] = exactitud_train
resultados_crossval_test[k, n] = exactitud_test
}
}
exact_train = rowMeans(resultados_crossval_train)
exact_test = rowMeans(resultados_crossval_test)
plot(valores, exact_train, col = 'darkblue', pch = 19, cex = 0.5, xlab = 'Valor de k', ylab = 'Exactitud', main = 'Exactitud en función del k')
lines(valores, exact_train, col = 'darkblue')
points(valores, exact_test, col = 'darkorange', pch = 19, cex = 0.5)
lines(valores, exact_test, col = 'darkorange')
legend('topright', legend = c('train', 'test'), col = c('darkblue', 'darkorange'), pch = 19)
mejor_k = which.max(exact_test)
mejor_k
library(rpart)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
indices = sample(seq(1:150), 30)
train = iris[-indices,]
test = iris[indices,-5]
fit <- rpart(Species~., data = train, method = 'class')
rpart.plot(fit)
predichos = predict(fit, newdata = test, type = "class")
confusionMatrix(predichos, iris[indices,5])
fit <- rpart(Species~., data = train, method = 'class', maxdepth = 1)
rpart.plot(fit)
predichos = predict(fit, newdata = test, type = "class")
acc = round(confusionMatrix(predichos, iris[indices,5])$overall[[1]], 3)
legend('topleft', legend = paste('Exactitud', as.character(acc)))
fit <- rpart(Species~., data = train, method = 'class', maxdepth = 2)
rpart.plot(fit)
predichos = predict(fit, newdata = test, type = "class")
acc = round(confusionMatrix(predichos, iris[indices,5])$overall[[1]], 3)
legend('topleft', legend = paste('Exactitud', as.character(acc)))
fit <- rpart(Species~., data = train, method = 'class', maxdepth = 3)
rpart.plot(fit)
predichos = predict(fit, newdata = test, type = "class")
acc = round(confusionMatrix(predichos, iris[indices,5])$overall[[1]], 3)
legend('topleft', legend = paste('Exactitud', as.character(acc)))
data_arboles <- read.csv('../../DataSets/arboles.csv')
data_arboles <- read.csv('arboles.csv')
data_arboles
colnames(data_arboles)
nombres = unique(data_arboles$nombre_com)
nombres
range(data_arboles$altura_tot)
range(data_arboles$diametro)
range(data_arboles$inclinacio)
#par(mfrow = c(2, 1))
b = seq(0,55,1)
l = length(nombres)
colores = viridis(l)
hist(data_arboles$'altura_tot'[data_arboles$nombre_com == 'Ceibo'], breaks = b, col = alpha(colores[1],0.5),  main = 'Histogramas de altura por especie', xlab = 'Altura', probability = TRUE)
for(a in 2:l){
hist(data_arboles$'altura_tot'[data_arboles$nombre_com == nombres[a]], breaks = b, col =     alpha(colores[a],0.5),  add = TRUE, probability = TRUE)
}
legend('right', legend = unique(data_arboles$nombre_com), col = viridis(l), pch = 19)
b = seq(0,310, 5)
colores = viridis(l)
hist(data_arboles$diametro[data_arboles$nombre_com == 'Jacarandá'], breaks = b, col = alpha(colores[1],0.5),  main = 'Histogramas de diámetro por especie', xlab = 'Diámetro', probability = TRUE, ylim = c(0, 0.08))
for(a in 2:l){
hist(data_arboles$'diametro'[data_arboles$nombre_com == nombres[a]], breaks = b, col =     alpha(colores[a],0.5),  add = TRUE, probability = TRUE)
}
legend('right', legend = unique(data_arboles$nombre_com), col = viridis(l), pch = 19)
plot(altura_tot~diametro, data = data_arboles, col = alpha(viridis(l)[nombre_com], 0.3), pch = 19, main = 'Scatterplot de árboles: altura y diámetro por especie', xlab = 'Diámetro', ylab = 'Altura')
legend('right', legend = nombres, col = viridis(l)[nombres], pch = 19)
Nrep = 1
Ptest = 0.2 # 20% de los datos para test
max_val = 30
valores = 1:max_val
resultados_crossval_train_arboles = matrix(NA, length(valores), Nrep)
resultados_crossval_test_arboles = matrix(NA, length(valores), Nrep)
atributos = c('altura_tot', 'diametro', 'inclinacio')
for(n in 1:Nrep){
indices = sample(seq(1, nrow(data_arboles)), Ptest*nrow(data_arboles))
test = data_arboles[indices, atributos]
train = data_arboles[-indices, atributos]
test_labels = data_arboles$nombre_com[indices]
train_labels = data_arboles$nombre_com[-indices]
for(k in 1:max_val){
clasif_arbol_train <- knn(train = train, test = train, cl = train_labels, k = k)
clasif_arbol_test <- knn(train = train, test = test, cl = train_labels, k = k)
exactitud_train = confusionMatrix(clasif_arbol_train, train_labels)$overall[[1]]
exactitud_test = confusionMatrix(clasif_arbol_test, test_labels)$overall[[1]]
resultados_crossval_train_arboles[k, n] = exactitud_train
resultados_crossval_test_arboles[k, n] = exactitud_test
}
}
exact_train_arbol = rowMeans(resultados_crossval_train_arboles)
exact_test_arbol = rowMeans(resultados_crossval_test_arboles)
plot(valores, exact_train_arbol, col = 'darkblue', pch = 19, cex = 0.5, ylim = c(0.7, 0.85), xlab = 'Valor de k', ylab = 'Exactitud', main = 'Exactitud en función del k')
lines(valores, exact_train_arbol, col = 'darkblue')
points(valores, exact_test_arbol, col = 'darkorange', pch = 19, cex = 0.5)
lines(valores, exact_test_arbol, col = 'darkorange')
legend('topright', legend = c('train', 'test'), col = c('darkblue', 'darkorange'), pch = 19)
data_arboles$altura_esc <- (data_arboles$altura_tot - min(data_arboles$altura_tot))/
(max(data_arboles$altura_tot) - min(data_arboles$altura_tot))
data_arboles$diametro_esc <- (data_arboles$diametro - min(data_arboles$diametro))/
(max(data_arboles$diametro) - min(data_arboles$diametro))
data_arboles$inclinacion_esc <- (data_arboles$inclinacio - min(data_arboles$inclinacio))/
(max(data_arboles$inclinacio) - min(data_arboles$inclinacio))
data_arboles$altura_esc <- (data_arboles$altura_tot - min(data_arboles$altura_tot))/
(max(data_arboles$altura_tot) - min(data_arboles$altura_tot))
data_arboles$diametro_esc <- (data_arboles$diametro - min(data_arboles$diametro))/
(max(data_arboles$diametro) - min(data_arboles$diametro))
data_arboles$inclinacion_esc <- (data_arboles$inclinacio - min(data_arboles$inclinacio))/
(max(data_arboles$inclinacio) - min(data_arboles$inclinacio))
Nrep = 1
Ptest = 0.2 # 20% de los datos para test
max_val = 50
valores = 1:max_val
atributos = c('altura_esc', 'diametro_esc', 'inclinacion_esc')
resultados_crossval_train_arboles = matrix(NA, length(valores), Nrep)
resultados_crossval_test_arboles = matrix(NA, length(valores), Nrep)
for(n in 1:Nrep){
indices = sample(seq(1, nrow(data_arboles)), Ptest*nrow(data_arboles))
test = data_arboles[indices, atributos]
train = data_arboles[-indices, atributos]
test_labels = data_arboles$nombre_com[indices]
train_labels = data_arboles$nombre_com[-indices]
for(k in 1:max_val){
clasif_arbol_train <- knn(train = train, test = train, cl = train_labels, k = k)
clasif_arbol_test <- knn(train = train, test = test, cl = train_labels, k = k)
exactitud_train = confusionMatrix(clasif_arbol_train, train_labels)$overall[[1]]
exactitud_test = confusionMatrix(clasif_arbol_test, test_labels)$overall[[1]]
resultados_crossval_train_arboles[k, n] = exactitud_train
resultados_crossval_test_arboles[k, n] = exactitud_test
}
}
exact_train_arbol = rowMeans(resultados_crossval_train_arboles)
exact_test_arbol = rowMeans(resultados_crossval_test_arboles)
plot(valores, exact_train_arbol, col = 'darkblue', pch = 19, cex = 0.5, ylim = c(0.7, 0.85), xlab = 'Valor de k', ylab = 'Exactitud', main = 'Exactitud en función del k')
lines(valores, exact_train_arbol, col = 'darkblue')
points(valores, exact_test_arbol, col = 'darkorange', pch = 19, cex = 0.5)
lines(valores, exact_test_arbol, col = 'darkorange')
legend('topright', legend = c('train', 'test'), col = c('darkblue', 'darkorange'), pch = 19)
columnas = c('altura_tot', 'diametro', 'inclinacio', 'nombre_com')
atributos = c('altura_tot', 'diametro', 'inclinacio')
indices = sample(seq(1,nrow(data_arboles)), 0.15*nrow(data_arboles))
train = data_arboles[-indices, columnas]
test = data_arboles[indices, atributos ]
fit <- rpart(nombre_com~., data = train, method = 'class')
rpart.plot(fit)
predichos = predict(fit, newdata = test, type = "class")
confusionMatrix(predichos, data_arboles$nombre_com[indices])
range(data_arboles$altura_tot)
range(data_arboles$diametro)
library(viridis) # opcional para tener los colores
library(ggplot2) # para tener el alpha para regular opacidad
library(class) # para el clasificador knn
library(caret) # para la confusionMatrix
library(rpart) # para usar árboles de decisión
library(rpart.plot) # para mostrar árboles de decisión
ggp <- ggpairs(data_arboles,
columns = c(2, 3, 89, 33),
mapping = ggplot2::aes(color = as.factor(data_arboles$nombre_com)))
View(data_arboles)
ggp <- ggpairs(data_arboles,
columns = c(1,2, 3),
mapping = ggplot2::aes(color = as.factor(data_arboles$nombre_com)))
print(ggp, progress = FALSE)
ggp <- ggpairs(data_arboles,
columns = c(1,2, 3,4),
mapping = ggplot2::aes(color = as.factor(data_arboles$nombre_com)))
print(ggp, progress = FALSE)
ggp <- ggpairs(data_arboles,
columns = c(1,2, 3,4),
mapping = ggplot2::aes(color = as.factor(data_arboles$nombre_com)))
print(ggp, progress = FALSE)
unlink("claseKNNclusteringArbolesDecision_cache", recursive = TRUE)
knitr::knit_exit()
Sys.sleep(100)
unlink("claseKNNclusteringArbolesDecision_cache", recursive = TRUE)
unlink()
k = 1 # elegir el k
Ptest = 0.2 # elegir el porcentaje de datos test
atributos = c('altura_tot', 'diametro', 'inclinacio')
indices = sample(seq(1, nrow(data_arboles)), Ptest*nrow(data_arboles))
test = data_arboles[indices, atributos]
train = data_arboles[-indices, atributos]
test_labels = data_arboles$nombre_com[indices]
train_labels = data_arboles$nombre_com[-indices]
clasif_arbol_train <- knn(train = train, test = train, cl = train_labels, k = k)
clasif_arbol_test <- knn(train = train, test = test, cl = train_labels, k = k)
exactitud_train = confusionMatrix(clasif_arbol_train, train_labels)$overall[[1]]
exactitud_test = confusionMatrix(clasif_arbol_test, test_labels)$overall[[1]]
