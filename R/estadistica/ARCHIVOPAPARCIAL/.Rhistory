main="Research and development expenditure (% of GDP)",lwd=2)
points(1996:2016,usa,type="l",lwd=2)
points(1996:2016,argen,type="l",col="lightblue",lwd=2)
points(1996:2016,ger,type="l",col="orange",lwd=2)
points(1996:2016,china,type="l",col="red",lwd=2)
points(1996:2016,japan,type="l",col="green",lwd=2)
points(1996:2016,finl,type="l",col="magenta",lwd=2)
points(1996:2016,uk,type="l",col="grey",lwd=2)
text(2015.2,japan[21]+0.3,labels="Japan",col="green")
text(2015.2,france[21]+0.15,labels="France",col="blue")
text(2015,ger[21]+0.1,labels="Germany",col="orange")
text(2015.8,usa[21]-0.1,labels="USA",col="black")
text(2015.2,china[21]-0.2,labels="China",col="red")
text(2014.8,argen[21]+0.2,labels="Argentina",col="lightblue")
text(2015.5,uk[21]-0.2,labels="UK",col="grey")
text(2012,finl[17]+0.4,labels="Finland",col="magenta")
# Estudiemos un modelo de regresion
set.seed(27)
entrena <- sample(c(TRUE,FALSE),nrow(rdpercentGDP),rep=TRUE,prob=c(0.8,0.2))
ajusteml<-lm(usa~.,data = rdpercentGDP[entrena,-1])
summary(ajusteml) #no dan significativas todas...
# Vemos que cambiando la semilla me da re diferente la estimacion
# será que esta todo super correlacionad??
XX <- model.matrix(ajusteml)[,-1] #sin el intercept
cor(rdpercentGDP[2:9]) #vemos que hay covariables que estan muy correlacionadas :(
# bonus track
# ¿Estan correlacionadas las variables?
library(regclass)
# bonus track
# ¿Estan correlacionadas las variables?
#library(regclass)
VIF(ajusteml)#vif>10 alta correlacion
# bonus track
# ¿Estan correlacionadas las variables?
#library(regclass)
VIF(ajusteml)#vif>10 alta correlacion
# bonus track
# ¿Estan correlacionadas las variables?
#library(regclass)
VIF(ajusteml)#vif>10 alta correlacion
# ¿Estan correlacionadas las variables?
#library(regclass)
VIF(ajusteml)#vif>10 alta correlacion
# bonus track
# ¿Estan correlacionadas las variables?
library(regclass)
VIF(ajusteml)#vif>10 alta correlacion
install.packages("regclass")
setwd("~/programas-algoritmos/R/estadistica/ARCHIVOPAPARCIAL")
# bonus track
# ¿Estan correlacionadas las variables?
library(regclass)
VIF(ajusteml)#vif>10 alta correlacion
# poner alpha = 0 para que haga el ajuste ridge
ajuste.ridge <- glmnet(XX,usa[entrena],alpha=0)
plot(ajuste.ridge,label = T,xvar="lambda",lwd=2,main="Ridge Regression")
ajuste.ridge$lambda
grilla <- 10^seq(10,-2,length=100)
grilla <- 10^seq(10,-2,length=100)
### elijo lambda por validaci�n cruzada
set.seed(21)
vcR <- cv.glmnet(XX,usa[entrena],alpha=0,lambda=grilla,nfolds = 5)
names(vcR)
vcR$lambda.min
vcR$lambda.1se
vcR$lambda.1se
rid.1se<-glmnet(XX,usa[entrena],alpha=0,lambda = vcR$lambda.1se)
ajusteml
## poner alpha=1 si queremos hacer LASSO
set.seed(87)
vcL <- cv.glmnet(XX,usa[entrena],alpha=1,lambda=grilla,nfolds = 5)
vcL <- cv.glmnet(XX,usa[entrena],alpha=1,lambda=grilla,nfolds = 5)
plot(vcL)
vcL$lambda.1se
vcL$lambda.1se
lasso.1se<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.1se)
lasso.min<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.min)
lasso.min<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.min)
coef(lasso.1se)
coef(lasso.min) ## selecciona mas variables
## el as.matrix es un comando que "salva" cuando se necesita objeto matriz
nuevo <- as.matrix(rdpercentGDP[prueba,-c(1,9)]) ## me quedo con la submatriz que contiene
## con todo el conjunto de datos, estimo los par�metros
covariables <- as.matrix(rdpercentGDP[,-c(1,9)])
salidaR <- glmnet(covariables,usa,alpha=0)
ecmL <- mean((lasso.pred-usa[prueba])^2)
rdpercentGDP <- read.csv("rdpercentGDP.csv",sep = "")
attach(rdpercentGDP)
names(rdpercentGDP)
head(rdpercentGDP)
par(mfrow=c(1,1))
plot(1996:2016,france,type="l",col="blue",ylim=c(0,3.8),xlab="years",ylab="R&D",
main="Research and development expenditure (% of GDP)",lwd=2)
points(1996:2016,usa,type="l",lwd=2)
points(1996:2016,argen,type="l",col="lightblue",lwd=2)
points(1996:2016,ger,type="l",col="orange",lwd=2)
points(1996:2016,china,type="l",col="red",lwd=2)
points(1996:2016,japan,type="l",col="green",lwd=2)
points(1996:2016,finl,type="l",col="magenta",lwd=2)
points(1996:2016,uk,type="l",col="grey",lwd=2)
text(2015.2,japan[21]+0.3,labels="Japan",col="green")
text(2015.2,france[21]+0.15,labels="France",col="blue")
text(2015,ger[21]+0.1,labels="Germany",col="orange")
text(2015.8,usa[21]-0.1,labels="USA",col="black")
text(2015.2,china[21]-0.2,labels="China",col="red")
text(2014.8,argen[21]+0.2,labels="Argentina",col="lightblue")
text(2015.5,uk[21]-0.2,labels="UK",col="grey")
text(2012,finl[17]+0.4,labels="Finland",col="magenta")
# Estudiemos un modelo de regresion
set.seed(27)
entrena <- sample(c(TRUE,FALSE),nrow(rdpercentGDP),rep=TRUE,prob=c(0.8,0.2))
ajusteml<-lm(usa~.,data = rdpercentGDP[entrena,-1])
summary(ajusteml) #no dan significativas todas...
# Vemos que cambiando la semilla me da re diferente la estimacion
# será que esta todo super correlacionad??
XX <- model.matrix(ajusteml)[,-1] #sin el intercept
cor(rdpercentGDP[2:9]) #vemos que hay covariables que estan muy correlacionadas :(
# bonus track
# ¿Estan correlacionadas las variables?
#library(regclass)
#VIF(ajusteml)#vif>10 alta correlacion
#ahora con Ridge, que es la penalizaci�n que se recomienda para estos casos
# poner alpha = 0 para que haga el ajuste ridge
ajuste.ridge <- glmnet(XX,usa[entrena],alpha=0)
names(ajuste.ridge)
summary(ajuste.ridge) ## no se entiende mucho
plot(ajuste.ridge,label = T,xvar="lambda",lwd=2,main="Ridge Regression")
abline(h=0,lty=2)
ajuste.ridge$lambda
coef.glmnet(ajuste.ridge) ## coeficientes para valores de lambda en ajuste.ridge$lambda
grilla <- 10^seq(10,-2,length=100)
### elijo lambda por validaci�n cruzada
set.seed(21)
vcR <- cv.glmnet(XX,usa[entrena],alpha=0,lambda=grilla,nfolds = 5)
plot(vcR)
names(vcR)
vcR$lambda.min
vcR$lambda.1se
rid.1se<-glmnet(XX,usa[entrena],alpha=0,lambda = vcR$lambda.1se)
rid.min<-glmnet(XX,usa[entrena],alpha=0,lambda = vcR$lambda.min)
coef(rid.1se)
coef(rid.min)
ajusteml
## poner alpha=1 si queremos hacer LASSO
set.seed(87)
vcL <- cv.glmnet(XX,usa[entrena],alpha=1,lambda=grilla,nfolds = 5)
plot(vcL)
vcL$lambda.min
vcL$lambda.1se
lasso.1se<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.1se)
lasso.min<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.min)
coef(lasso.1se)
coef(lasso.min) ## selecciona mas variables
### medimos la capacidad de predicci�n
prueba <-(!entrena)
is.matrix(rdpercentGDP[prueba,-c(1,9)]) ## no consideramos a la primera y última columna
## el as.matrix es un comando que "salva" cuando se necesita objeto matriz
nuevo <- as.matrix(rdpercentGDP[prueba,-c(1,9)]) ## me quedo con la submatriz que contiene
## a las filas de prueba de las covariables involucradas
## Ridge
ridge.pred <- predict(rid.1se,s=vcR$lambda.1se,newx=nuevo)
ecmR <- mean((ridge.pred-usa[prueba])^2)
## con todo el conjunto de datos, estimo los par�metros
covariables <- as.matrix(rdpercentGDP[,-c(1,9)])
salidaR <- glmnet(covariables,usa,alpha=0)
predict(salidaR,type="coefficients",s=vcR$lambda.1se)[1:8,]
## LASSO
lasso.pred <- predict(lasso.1se,s=vcL$lambda.1se,newx=nuevo)
ecmL <- mean((lasso.pred-usa[prueba])^2)
## ahora con todo el conjunto de datos, estimo los par�metros
salidaL <- glmnet(covariables,usa,alpha=1)
predict(salidaL,type="coefficients",s=vcL$lambda.1se)[1:8,]
c(ecmR,ecmL) ## da mejor error de predicci�n ridge
coef.glmnet(ajuste.ridge) ## coeficientes para valores de lambda en ajuste.ridge$lambda
# ESTIMAR COPEFICIENTES
#cargo los datos
datos<-cars
names(datos)
#defino las variables
x<-datos$speed #velocidad del auto
y<-datos$dist #distancia requerida de frenado
plot(x,y)
# armamos a mano la matriz de diseño
X<-cbind(rep(1,length(x)),x)
#calculamos usando la formula
beta_sombrero<-solve(t(X)%*%X)%*%t(X)%*%y
beta_sombrero0<-beta_sombrero[1]
beta_sombrero1<-beta_sombrero[2]
#graficamos la recta
plot(x,y,pch=20)
abline(beta_sombrero,col="dodgerblue3", lwd=2)#, lty=2)
#superponemos las estimaciones de nuestros puntos de diseño
y_sombrero<-beta_sombrero0+beta_sombrero1*x
points(x,y_sombrero,col="orange", pch=18)
# estimamos sigma^2
sum((y-y_sombrero)^2)/(length(x)-2)
# para agregar mas covariables
x2<-x^2
reg2<-lm(y~x+x2)
summary(reg2)
#graficamos
y2<-reg2$coefficients[1]+reg2$coefficients[2]*x+reg2$coefficients[3]*x2
lines(x,y2, col="darkolivegreen", lwd=2)
# Una no lineal
#######################################################
rm(list=ls())
## Simulacion
sigma<-sqrt(1.3)
beta.star0<- 0.1
beta.star1<- 0.025
equis<- seq(1,10, by=0.1)
set.seed(123)
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
# con puntos
plot(equis,y,pch=20,col="grey30",xlab="x",ylim=c(0,10))
#grafico la verdadera
lines(equis,z,lwd=2,col="magenta")
###########################################################
#
#Ajusto un modelo lineal simple
#
#E(Y)= beta_0+beta_1*equis
#
###########################################################
salida.lineal<- lm(y~equis)
lines(equis,salida.lineal$fit,col="orange",lwd=2)
###########################################################
#
#Ajusto un modelo una cuadratica
#
#E(Y)= beta_0+beta_1*equis+beta_2*equis^2
#
###########################################################
plot(equis,y,pch=20,col="grey30",xlab="x",ylim=c(0,10))
lines(equis,z,lwd=2)
salida<- lm(y~poly(equis,2,raw=TRUE))
lines(equis,salida$fit,col="orange",lwd=2)
###########################################################
#
#Ajusto un modelo un polinomio de grado 5
#
#E(Y)= beta_0+beta_1*equis+...+beta_5*equis^5
#
###########################################################
plot(equis,y,pch=20,col="grey30",xlab="x",ylim=c(0,10))
lines(equis,z,lwd=2)
salida<- lm(y~poly(equis,5,raw=TRUE))
lines(equis,salida$fit,col="orange",lwd=2)
colores<-rainbow(9)
###########################################################
#
# Ahora lo repito 9 veces y grafico las rectas ajustadas
#
###########################################################
# sin puntos
plot(equis,y,pch=20,col="grey30",xlab="x",type="n",ylim=c(0,10))
lines(equis,z,lwd=2)
set.seed(123)
for(i in 1: 9){
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
salida.lineal<- lm(y~equis)
lines(equis,salida.lineal$fit,col=colores[i],lwd=2)
}
lines(equis,z,lwd=2)
#points(equis,y)
###########################################################
#
# Repito 9 veces y grafico las cuadraticas ajustadas
#
###########################################################
### Ahora ajusto cuadraticas
set.seed(123)
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
plot(equis,y,pch=20,col="grey30",xlab="x",type="n",ylim=c(0,10))
lines(equis,z,lwd=2)
salida<- lm(y~poly(equis,2,raw=TRUE))
lines(equis,salida$fit,col=15,lwd=2)
for(i in 1:9){
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
salida<- lm(y~poly(equis,2,raw=TRUE))
lines(equis,salida$fit,col=colores[i],lwd=2)
}
lines(equis,z,lwd=2)
#points(equis,y)
###########################################################
#
# 9 veces y grafico los polinomio de grado 5 ajustados
#
###########################################################
set.seed(123)
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
plot(equis,y,pch=20,col="grey30",xlab="x",type="n",ylim=c(-1,10))
lines(equis,z,lwd=2)
salida<- lm(y~poly(equis,5,raw=TRUE))
lines(equis,salida$fit,col="orange",lwd=2)
for(i in 1: 9){
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
salida<- lm(y~poly(equis,5,raw=TRUE))
lines(equis,salida$fit,col=colores[i],lwd=2)
}
lines(equis,z,lwd=2)
###########################################################
#
# Vamos a predecir con los distintos ajustes en x_o=4
# Repetimos Nrep=1000 veces
#
###########################################################
Nrep<- 1000
set.seed(123)
pred1<-pred2<-pred5<-pred10<-pred15<-c()
equis.new<- data.frame(equis=c(4))
for(i in 1: Nrep){
z<- exp(beta.star0+beta.star1*equis*equis)
y<- z+rnorm(length(equis),0,sigma)
salida1<- lm(y~equis)
salida2<- lm(y~poly(equis,2,raw=TRUE))
salida5<- lm(y~poly(equis,5,raw=TRUE))
salida10<- lm(y~poly(equis,10,raw=TRUE))
salida15<- lm(y~poly(equis,15,raw=TRUE))
pred1<-c(pred1,predict(salida1,newdata=equis.new))
pred2<-c(pred2,predict(salida2,newdata=equis.new))
pred5<-c(pred5,predict(salida5,newdata=equis.new))
pred10<-c(pred10,predict(salida10,newdata=equis.new))
pred15<-c(pred15,predict(salida15,newdata=equis.new))
}
boxplot(pred1,pred2,pred5,pred10,pred15,names=c("1","2","5","10","15"),xlab="Grado del Polinomio")
abline(h=exp(beta.star0+beta.star1*4*4),lwd=2,col="magenta")
nbp <- read.table("bajoPeso.txt",header=TRUE)
names(nbp)
m <- dim(nbp)
attach(nbp)
plot(apgar5,presSist)
ajuste <- lm(presSist~edadG+apgar5)
names(ajuste)
summary(ajuste)
names(summary(ajuste))
summary(ajuste)$sigma
sum(ajuste$coefficients*c(1,31,7))
install.packages("ISLR")
install.packages("plotmo")     # para graficar
install.packages("glmnet")
install.packages("regclass")
rm(list=ls())
#cargo librerias
library(ISLR)
library(plotmo)     # para graficar
library(glmnet)
#cargo datos
#fix(Hitters)
names(Hitters)
dim(Hitters)
#Chequeo missings
sum(is.na(Hitters$Salary))
Hitters<- na.omit(Hitters)
sum(is.na(Hitters$Salary))
dim(Hitters)
# Ajustamos minimos cuadrados con todas las covariables
summary(lm(Salary~.,Hitters))
#Creamos la muestra de entrenamiento y de validacion
set.seed(1)
train <- sample(c(TRUE,FALSE), nrow(Hitters),rep=TRUE)
test <- (!train )
#Creo la matriz de dise�o y vector de respuestas
x <- model.matrix(Salary~.,Hitters)[,-1]
y <- Hitters$Salary
y.test=y[test]
# Calculo LASSO
grid<- 10^seq(10,-2,length=100)
lasso.mod =glmnet (x[train ,],y[train],alpha =1, lambda =grid) #por default estandariza variables
## Veo los coeficientes
dim(coef(lasso.mod))
lasso.mod$lambda
#Inpeccionamos para distintos valores de lambda
lasso.mod$lambda[90]
coef(lasso.mod)[,90]
lasso.mod$lambda[70]
coef(lasso.mod)[,70]
lasso.mod$lambda[30]
coef(lasso.mod)[,30]
## Grafico
plot(lasso.mod)
plot(lasso.mod,label=T,xvar="lambda")
#Creo la matriz de dise�o y vector de respuestas
x <- model.matrix(Salary~.,Hitters)[,-1]
y <- Hitters$Salary
y.test=y[test]
#LASSO
set.seed(1)
cv.out <- cv.glmnet(x[train,],y[train],alpha =1)
plot(cv.out)
bestlam <- cv.out$lambda.min
log(bestlam)
#miro cuanto vale el MSE en la muestra de validacion
coef(lasso.mod,s=cv.out$lambda.min)
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)
#Tmb tenemos el log de la regla de 1 desvio standard
log(cv.out$lambda.1se)
coef(lasso.mod,s=cv.out$lambda.1se)
lasso.pred=predict(lasso.mod,s=cv.out$lambda.1se,newx=x[test,])
mean((lasso.pred-y.test)^2)
###############################
##Comparamos con Ridge
# Calculo Ridge
grid<- 10^seq(10,-2,length=100)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid) #por defalut estandariza variables
plot(ridge.mod)
plot(ridge.mod,label=T,xvar="lambda")
#Ridge
set.seed(1)
cv.out <- cv.glmnet(x[train,],y[train],alpha =0)
plot(cv.out)
bestlam <- cv.out$lambda.min
log(bestlam)
#miro cuanto vale el MSE n la muestra de validacion
coef(ridge.mod,s=cv.out$lambda.min)
ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-y.test)^2)
rdpercentGDP <- read.csv("rdpercentGDP.csv",sep = "")
attach(rdpercentGDP)
names(rdpercentGDP)
head(rdpercentGDP)
par(mfrow=c(1,1))
plot(1996:2016,france,type="l",col="blue",ylim=c(0,3.8),xlab="years",ylab="R&D",
main="Research and development expenditure (% of GDP)",lwd=2)
points(1996:2016,usa,type="l",lwd=2)
points(1996:2016,argen,type="l",col="lightblue",lwd=2)
points(1996:2016,ger,type="l",col="orange",lwd=2)
points(1996:2016,china,type="l",col="red",lwd=2)
points(1996:2016,japan,type="l",col="green",lwd=2)
points(1996:2016,finl,type="l",col="magenta",lwd=2)
points(1996:2016,uk,type="l",col="grey",lwd=2)
text(2015.2,japan[21]+0.3,labels="Japan",col="green")
text(2015.2,france[21]+0.15,labels="France",col="blue")
text(2015,ger[21]+0.1,labels="Germany",col="orange")
text(2015.8,usa[21]-0.1,labels="USA",col="black")
text(2015.2,china[21]-0.2,labels="China",col="red")
text(2014.8,argen[21]+0.2,labels="Argentina",col="lightblue")
text(2015.5,uk[21]-0.2,labels="UK",col="grey")
text(2012,finl[17]+0.4,labels="Finland",col="magenta")
# Estudiemos un modelo de regresion
set.seed(27)
entrena <- sample(c(TRUE,FALSE),nrow(rdpercentGDP),rep=TRUE,prob=c(0.8,0.2))
ajusteml<-lm(usa~.,data = rdpercentGDP[entrena,-1])
summary(ajusteml) #no dan significativas todas...
# Vemos que cambiando la semilla me da re diferente la estimacion
# será que esta todo super correlacionad??
XX <- model.matrix(ajusteml)[,-1] #sin el intercept
cor(rdpercentGDP[2:9]) #vemos que hay covariables que estan muy correlacionadas :(
# bonus track
# ¿Estan correlacionadas las variables?
#library(regclass)
#VIF(ajusteml)#vif>10 alta correlacion
#ahora con Ridge, que es la penalizaci�n que se recomienda para estos casos
# poner alpha = 0 para que haga el ajuste ridge
ajuste.ridge <- glmnet(XX,usa[entrena],alpha=0)
names(ajuste.ridge)
summary(ajuste.ridge) ## no se entiende mucho
plot(ajuste.ridge,label = T,xvar="lambda",lwd=2,main="Ridge Regression")
abline(h=0,lty=2)
ajuste.ridge$lambda
coef.glmnet(ajuste.ridge) ## coeficientes para valores de lambda en ajuste.ridge$lambda
grilla <- 10^seq(10,-2,length=100)
### elijo lambda por validaci�n cruzada
set.seed(21)
vcR <- cv.glmnet(XX,usa[entrena],alpha=0,lambda=grilla,nfolds = 5)
plot(vcR)
names(vcR)
vcR$lambda.min
vcR$lambda.1se
rid.1se<-glmnet(XX,usa[entrena],alpha=0,lambda = vcR$lambda.1se)
rid.min<-glmnet(XX,usa[entrena],alpha=0,lambda = vcR$lambda.min)
coef(rid.1se)
coef(rid.min)
ajusteml
## poner alpha=1 si queremos hacer LASSO
set.seed(87)
vcL <- cv.glmnet(XX,usa[entrena],alpha=1,lambda=grilla,nfolds = 5)
plot(vcL)
vcL$lambda.min
vcL$lambda.1se
lasso.1se<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.1se)
lasso.min<-glmnet(XX,usa[entrena],alpha=1,lambda = vcL$lambda.min)
coef(lasso.1se)
coef(lasso.min) ## selecciona mas variables
### medimos la capacidad de predicci�n
prueba <-(!entrena)
is.matrix(rdpercentGDP[prueba,-c(1,9)]) ## no consideramos a la primera y última columna
## el as.matrix es un comando que "salva" cuando se necesita objeto matriz
nuevo <- as.matrix(rdpercentGDP[prueba,-c(1,9)]) ## me quedo con la submatriz que contiene
## a las filas de prueba de las covariables involucradas
## Ridge
ridge.pred <- predict(rid.1se,s=vcR$lambda.1se,newx=nuevo)
ecmR <- mean((ridge.pred-usa[prueba])^2)
## con todo el conjunto de datos, estimo los par�metros
covariables <- as.matrix(rdpercentGDP[,-c(1,9)])
salidaR <- glmnet(covariables,usa,alpha=0)
predict(salidaR,type="coefficients",s=vcR$lambda.1se)[1:8,]
## LASSO
lasso.pred <- predict(lasso.1se,s=vcL$lambda.1se,newx=nuevo)
ecmL <- mean((lasso.pred-usa[prueba])^2)
## ahora con todo el conjunto de datos, estimo los par�metros
salidaL <- glmnet(covariables,usa,alpha=1)
predict(salidaL,type="coefficients",s=vcL$lambda.1se)[1:8,]
c(ecmR,ecmL) ## da mejor error de predicci�n ridge
install.packages("ISLR")
